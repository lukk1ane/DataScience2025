{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f8eb9d7",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5f53e888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 city                      job      company department  count\n",
      "0           East Jill  Chief Financial Officer  Hoffman Ltd    Finance     31\n",
      "1           East Jill  Chief Financial Officer  Hoffman Ltd         HR     26\n",
      "2           East Jill  Chief Financial Officer  Hoffman Ltd         IT     34\n",
      "3           East Jill  Chief Financial Officer  Hoffman Ltd  Marketing     33\n",
      "4           East Jill  Chief Financial Officer  Hoffman Ltd      Sales     40\n",
      "..                ...                      ...          ...        ...    ...\n",
      "295  North Judithbury             Town planner    Wolfe LLC    Finance     30\n",
      "296  North Judithbury             Town planner    Wolfe LLC         HR     34\n",
      "297  North Judithbury             Town planner    Wolfe LLC         IT     28\n",
      "298  North Judithbury             Town planner    Wolfe LLC  Marketing     33\n",
      "299  North Judithbury             Town planner    Wolfe LLC      Sales     38\n",
      "\n",
      "[300 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "random.seed(42)\n",
    "Faker.seed(42)  \n",
    "\n",
    "\n",
    "cities = [fake.city() for _ in range(3)]\n",
    "jobs = [fake.job() for _ in range(5)]\n",
    "companies = [fake.company() for _ in range(4)]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'city': [random.choice(cities) for _ in range(10000)],\n",
    "    'job': [random.choice(jobs) for _ in range(10000)],\n",
    "    'company': [random.choice(companies) for _ in range(10000)],\n",
    "    'department': [random.choice(['Sales', 'HR', 'IT', 'Finance', 'Marketing']) for _ in range(10000)]\n",
    "})\n",
    "\n",
    "combo_counts = df.value_counts(sort = False) \n",
    "popular = combo_counts[combo_counts >= 10].reset_index(name='count')\n",
    "\n",
    "print(popular)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9664304",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a0b01196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        index  missing_count\n",
      "1       email            546\n",
      "3         age            516\n",
      "4  department            503\n",
      "2        city            498\n",
      "0        name            496\n",
      "========================================\n",
      "        index  missing_count\n",
      "1       email            546\n",
      "3         age            516\n",
      "4  department            503\n",
      "========================================\n",
      "              name                         email              city   age  \\\n",
      "7              NaN  hendersonvanessa@example.com               NaN  22.0   \n",
      "9              NaN            luis11@example.com               NaN  42.0   \n",
      "10             NaN           rarnold@example.net               NaN  39.0   \n",
      "17             NaN   christinebecker@example.com               NaN  64.0   \n",
      "25             NaN           xmalone@example.org  Port Cherylville  63.0   \n",
      "..             ...                           ...               ...   ...   \n",
      "937   James Reeves    carpenterjorge@example.net  East Stevenville  59.0   \n",
      "939   Erica Nelson     stewartalyssa@example.org      West Anthony  32.0   \n",
      "958            NaN           unguyen@example.net         West Erin  25.0   \n",
      "986            NaN           nturner@example.com         Maryville  54.0   \n",
      "992  Lori Castillo        hhenderson@example.org               NaN  50.0   \n",
      "\n",
      "    department  \n",
      "7      Finance  \n",
      "9      Finance  \n",
      "10          HR  \n",
      "17       Sales  \n",
      "25     Finance  \n",
      "..         ...  \n",
      "937         IT  \n",
      "939    Finance  \n",
      "958         IT  \n",
      "986    Finance  \n",
      "992    Finance  \n",
      "\n",
      "[101 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "def maybe_missing(value, prob=0.5):\n",
    "    \"\"\"Return the value or np.nan with probability `prob`.\"\"\"\n",
    "    return value if random.random() > prob else np.nan\n",
    "\n",
    "n = 1000\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'name': [maybe_missing(fake.name()) for _ in range(n)],\n",
    "    'email': [maybe_missing(fake.email()) for _ in range(n)],\n",
    "    'city': [maybe_missing(fake.city()) for _ in range(n)],\n",
    "    'age': [maybe_missing(random.randint(18, 65)) for _ in range(n)],\n",
    "    'department': [maybe_missing(random.choice(['IT', 'Sales', 'HR', 'Finance'])) for _ in range(n)]\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "missing_values = df.isna().sum(axis=0).reset_index(name='missing_count').sort_values(by='missing_count', ascending=False)\n",
    "\n",
    "print(missing_values)\n",
    "print('=='*20)\n",
    "top_3_missing = missing_values.head(3)\n",
    "print(top_3_missing)\n",
    "index = top_3_missing['index'].tolist()\n",
    "removed_nans = df.dropna(subset=index)\n",
    "print('=='*20)\n",
    "print(removed_nans)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca264259",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6d4298c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id             name                    email  country department   age  \\\n",
      "0   1  Angela Robinson      cindy12@example.org      USA         HR  56.0   \n",
      "1   2       Henry Cain   yschneider@example.net   Canada      Sales  35.0   \n",
      "2   3  Jenny Rasmussen  floresjoyce@example.com  Germany    Finance  34.0   \n",
      "3   4      Dean Turner     dillon46@example.org   Canada      Sales  42.0   \n",
      "4   5   Justin Shelton        trice@example.org       UK         HR  29.0   \n",
      "\n",
      "     salary  is_remote   join_date  \n",
      "0   3937.74      False  2022-12-30  \n",
      "1       NaN      False  2025-07-10  \n",
      "2  10272.36      False  2022-03-11  \n",
      "3  13400.24      False  2021-05-29  \n",
      "4   7081.08      False  2024-12-31  \n"
     ]
    }
   ],
   "source": [
    "n = 100_000  # number of rows\n",
    "\n",
    "def maybe_missing(value, prob=0.1):\n",
    "    \"\"\"Return NaN with probability `prob`.\"\"\"\n",
    "    return value if random.random() > prob else np.nan\n",
    "\n",
    "# some limited categories to make realistic repetition\n",
    "departments = ['IT', 'Sales', 'HR', 'Finance', 'Marketing']\n",
    "countries = ['USA', 'Germany', 'France', 'Japan', 'UK', 'Canada']\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'id': range(1, n + 1),  # integer id\n",
    "    'name': [maybe_missing(fake.name(), 0.05) for _ in range(n)],  # string\n",
    "    'email': [maybe_missing(fake.email(), 0.05) for _ in range(n)],  # string\n",
    "    'country': [maybe_missing(random.choice(countries), 0.1) for _ in range(n)],  # categorical-like\n",
    "    'department': [maybe_missing(random.choice(departments), 0.1) for _ in range(n)],\n",
    "    'age': [maybe_missing(random.randint(18, 65), 0.05) for _ in range(n)],  # numeric int\n",
    "    'salary': [maybe_missing(round(random.uniform(2000, 15000), 2), 0.05) for _ in range(n)],  # numeric float\n",
    "    'is_remote': [random.choice([True, False]) for _ in range(n)],  # boolean\n",
    "    'join_date': [maybe_missing(fake.date_between(start_date='-5y', end_date='today'), 0.05) for _ in range(n)]  # datetime\n",
    "})\n",
    "\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1bff88cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                             1\n",
      "name               Michael Smith\n",
      "email         ksmith@example.com\n",
      "country                   France\n",
      "department                    HR\n",
      "age                         65.0\n",
      "salary                   3578.31\n",
      "is_remote                  False\n",
      "join_date             2024-07-23\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "most_frequent_values_per_column = df.apply(lambda col: col.value_counts().idxmax())\n",
    "\n",
    "print(most_frequent_values_per_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc20180",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5de96c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Employee ID        Date  Hours Worked\n",
      "4911            1  2023-11-06           9.4\n",
      "8181            1  2023-11-07           9.0\n",
      "2394            1  2023-11-16           NaN\n",
      "8942            1  2023-11-16           8.7\n",
      "6594            1  2023-11-28           6.4\n",
      "...           ...         ...           ...\n",
      "320             1  2024-11-21           6.9\n",
      "9819            1  2024-11-24           6.3\n",
      "4140            1  2024-11-29           7.2\n",
      "7400            1  2024-12-01           8.3\n",
      "8523            1  2024-12-03           6.1\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "n = 10_000  # number of rows\n",
    "\n",
    "def maybe_missing(value, prob=0.05):\n",
    "    \"\"\"Return np.nan with probability `prob`.\"\"\"\n",
    "    return value if random.random() > prob else np.nan\n",
    "\n",
    "# Create DataFrame\n",
    "df_hours = pd.DataFrame({\n",
    "    'Employee ID': [random.randint(1, 50) for _ in range(n)],  # 50 employees\n",
    "    'Date': [maybe_missing(fake.date_between(start_date='-2y', end_date='today')) for _ in range(n)],\n",
    "    'Hours Worked': [maybe_missing(round(random.uniform(6, 10), 1)) for _ in range(n)]\n",
    "})\n",
    "\n",
    "df_hours.sort_values(by=['Employee ID', 'Date'], inplace=True)\n",
    "print(df_hours.head(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9e684e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Employee ID       Date  Hours Worked\n",
      "4911            1 2023-11-06           9.4\n",
      "8181            1 2023-11-07           9.0\n",
      "8942            1 2023-11-16           8.7\n",
      "6594            1 2023-11-28           6.4\n",
      "3254            1 2023-12-03           9.6\n",
      "...           ...        ...           ...\n",
      "9441           50 2025-09-27           9.4\n",
      "8423           50 2025-10-06          10.0\n",
      "5709           50 2025-10-21           8.7\n",
      "2761           50 2025-10-22           6.4\n",
      "3885           50 2025-10-25           8.7\n",
      "\n",
      "[7993 rows x 3 columns]\n",
      "      Employee ID       Date  Hours Worked\n",
      "4911            1 2023-11-06           9.4\n",
      "8181            1 2023-11-07           9.0\n",
      "8942            1 2023-11-16           8.7\n",
      "6594            1 2023-11-28           6.4\n",
      "3254            1 2023-12-03           9.6\n",
      "...           ...        ...           ...\n",
      "9441           50 2025-09-27           9.4\n",
      "8423           50 2025-10-06          10.0\n",
      "5709           50 2025-10-21           8.7\n",
      "2761           50 2025-10-22           6.4\n",
      "3885           50 2025-10-25           8.7\n",
      "\n",
      "[7993 rows x 3 columns]\n",
      "Employees with >=5 consecutive days: [ 2  8 15 16 21 24 29 33 39 47 49]\n",
      "\n",
      "Example streaks (Employee ID, start, end, length):\n",
      "      Employee ID  streak_id start_date   end_date  days_worked\n",
      "161             2         29 2024-05-09 2024-05-14            6\n",
      "953             8         74 2025-01-13 2025-01-18            6\n",
      "1815           15         72 2024-12-30 2025-01-03            5\n",
      "1880           16         17 2024-02-13 2024-02-18            6\n",
      "1899           16         36 2024-05-27 2024-06-01            6\n",
      "2515           21         33 2024-05-27 2024-05-31            5\n",
      "2595           21        113 2025-10-08 2025-10-12            5\n",
      "2868           24         10 2023-12-18 2023-12-22            5\n",
      "3492           29          7 2023-12-14 2023-12-18            5\n",
      "4043           33         61 2024-10-11 2024-10-15            5\n",
      "4818           39        102 2025-07-13 2025-07-17            5\n",
      "5727           47         24 2024-02-23 2024-02-27            5\n",
      "6071           49        111 2025-06-12 2025-06-16            5\n"
     ]
    }
   ],
   "source": [
    "df_hours[\"Date\"]  = pd.to_datetime(df_hours[\"Date\"], errors='coerce')\n",
    "\n",
    "df_hours.dropna(subset=[\"Date\"], inplace=True)\n",
    "\n",
    "worked_mask = df_hours['Hours Worked'].notna() & (df_hours['Hours Worked'] > 0)\n",
    "df_hours = df_hours[worked_mask]\n",
    "print(df_hours)\n",
    "\n",
    "df_hours = df_hours.drop_duplicates(subset=['Employee ID', 'Date'])\n",
    "print(df_hours)\n",
    "\n",
    "df_hours['prev_date'] = df_hours.groupby('Employee ID')['Date'].shift(1)\n",
    "df_hours['gap_days'] = (df_hours['Date'] - df_hours['prev_date']).dt.days\n",
    "\n",
    "df_hours['new_streak'] = (df_hours['gap_days'] != 1)  # True when streak breaks or first record\n",
    "df_hours['streak_id'] = df_hours.groupby('Employee ID')['new_streak'].cumsum()\n",
    "\n",
    "streaks = (\n",
    "    df_hours.groupby(['Employee ID', 'streak_id'], as_index=False)\n",
    "      .agg(start_date=('Date', 'min'),\n",
    "           end_date=('Date', 'max'),\n",
    "           days_worked=('Date', 'count'))\n",
    ")\n",
    "\n",
    "long_streaks = streaks[streaks['days_worked'] >= 5]\n",
    "\n",
    "employees_with_5plus = long_streaks['Employee ID'].unique()\n",
    "\n",
    "print(\"Employees with >=5 consecutive days:\", employees_with_5plus)\n",
    "print(\"\\nExample streaks (Employee ID, start, end, length):\")\n",
    "print(long_streaks.sort_values(['Employee ID', 'start_date']).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bf5adb",
   "metadata": {},
   "source": [
    "# Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bb782f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range(start=\"2023-01-01\", end=\"2024-12-31\", freq=\"D\")\n",
    "\n",
    "# Create daily sales data\n",
    "df = pd.DataFrame({\n",
    "    \"Date\": dates,\n",
    "    \"Sales\": [round(random.uniform(1000, 5000), 2) for _ in range(len(dates))],\n",
    "    \"Region\": [random.choice([\"East\", \"West\", \"North\", \"South\"]) for _ in range(len(dates))],\n",
    "    \"Store\": [fake.company() for _ in range(len(dates))]\n",
    "})\n",
    "\n",
    "# Make Date the index\n",
    "df.set_index(\"Date\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4f642a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q1 sums per month per year:\n",
      "                Sales                                             Region  \\\n",
      "Year Month                                                                 \n",
      "2023 1      100570.00  SouthSouthNorthSouthNorthEastSouthSouthNorthSo...   \n",
      "     2       90499.07  NorthWestWestNorthNorthWestEastWestEastSouthSo...   \n",
      "     3       88455.02  NorthWestSouthWestSouthSouthWestEastSouthEastW...   \n",
      "2024 1       92333.08  WestEastNorthWestEastSouthEastSouthWestEastSou...   \n",
      "     2       89962.54  SouthSouthNorthWestEastEastWestSouthNorthEastN...   \n",
      "     3       90695.93  SouthEastSouthEastNorthSouthNorthSouthNorthSou...   \n",
      "\n",
      "                                                        Store  \n",
      "Year Month                                                     \n",
      "2023 1      Booker IncMedina, Baker and ArnoldPayne, Matth...  \n",
      "     2      Camacho-WalkerWatkins-MartinezManning, Nelson ...  \n",
      "     3      Moore, Brown and LoveHowell GroupHunter, Henry...  \n",
      "2024 1      Cruz-WilliamsPoole-ClarkLong, Fowler and Bolto...  \n",
      "     2      Smith, Lucas and PerezLewis, Smith and CooperB...  \n",
      "     3      Thompson-WrightWilliams IncClark GroupDoyle an...  \n"
     ]
    }
   ],
   "source": [
    "monthly_data = df.resample('ME').sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "q1_sales = monthly_data[monthly_data.index.month.isin([1, 2, 3])]\n",
    "\n",
    "\n",
    "q1_sums = q1_sales.groupby([q1_sales.index.year, q1_sales.index.month]).sum()\n",
    "q1_sums.index.names = [\"Year\", \"Month\"]\n",
    "print(\"\\nQ1 sums per month per year:\")\n",
    "print(q1_sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2ee873",
   "metadata": {},
   "source": [
    "# Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0c805dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample transactions:\n",
      "   Transaction ID                   Customer    Value        Date\n",
      "0               1             Angela Johnson   402.62  2025-07-25\n",
      "1               2             Jillian Martin  2661.88  2025-04-18\n",
      "2               3            Mark Sanders MD  4961.40  2025-05-14\n",
      "3               4                Edwin Allen  1230.38  2025-01-05\n",
      "4               5  Mr. Christopher Daugherty  3507.66  2025-06-01\n"
     ]
    }
   ],
   "source": [
    "n = 10000\n",
    "\n",
    "df_sales = pd.DataFrame({\n",
    "    'Transaction ID': range(1, n+1),\n",
    "    'Customer': [fake.name() for _ in range(n)],\n",
    "    'Value': [round(random.uniform(10, 5000), 2) for _ in range(n)],\n",
    "    'Date': [fake.date_between(start_date='-1y', end_date='today') for _ in range(n)]\n",
    "})\n",
    "\n",
    "print(\"Sample transactions:\")\n",
    "print(df_sales.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "40297cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original rows: 10000, After filtering: 9500\n",
      "Filtered transactions:\n",
      "      Transaction ID              Customer    Value        Date\n",
      "470              471         Glenn Mcclure  4718.93  2025-06-09\n",
      "5763            5764         Jason Johnson  4718.85  2025-09-25\n",
      "8550            8551     Amanda Obrien DDS  4718.84  2024-12-06\n",
      "2520            2521  Dr. Katie Thomas DDS  4718.31  2024-12-12\n",
      "7718            7719        Sheryl Vaughan  4718.23  2025-09-15\n"
     ]
    }
   ],
   "source": [
    "threshold = df_sales['Value'].quantile(0.95)  \n",
    "df_filtered = df_sales[df_sales['Value'] <= threshold]\n",
    "\n",
    "print(f\"\\nOriginal rows: {len(df_sales)}, After filtering: {len(df_filtered)}\")\n",
    "\n",
    "print(\"Filtered transactions:\")\n",
    "print(df_filtered.sort_values(by='Value', ascending=False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088619b1",
   "metadata": {},
   "source": [
    "# Task 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8da48a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Measurement\n",
      "Date                   \n",
      "2024-11-01        20.40\n",
      "2024-11-02        25.10\n",
      "2024-11-04        84.98\n",
      "2024-11-05        81.85\n",
      "2024-11-05          NaN\n",
      "2024-11-06        84.24\n",
      "2024-11-06        46.47\n",
      "2024-11-06        30.68\n",
      "2024-11-06        49.37\n",
      "2024-11-07        81.37\n"
     ]
    }
   ],
   "source": [
    "n = 365\n",
    "dates = sorted(fake.date_between(start_date='-1y', end_date='today') for _ in range(n))\n",
    "\n",
    "values = [round(random.uniform(10, 100), 2) if random.random() > 0.1 else np.nan for _ in range(n)]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Date': dates,\n",
    "    'Measurement': values\n",
    "})\n",
    "\n",
    "df.set_index('Date', inplace=True)\n",
    "df.sort_index(inplace=True)  \n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9f048249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Measurement  7d_moving_avg\n",
      "Date                                  \n",
      "2024-11-01        20.40      20.400000\n",
      "2024-11-02        25.10      22.750000\n",
      "2024-11-04        84.98      43.493333\n",
      "2024-11-05        81.85      53.082500\n",
      "2024-11-05          NaN      53.082500\n",
      "2024-11-06        84.24      59.314000\n",
      "2024-11-06        46.47      57.173333\n",
      "2024-11-06        30.68      53.388571\n",
      "2024-11-06        49.37      52.886250\n",
      "2024-11-07        81.37      56.051111\n",
      "2024-11-08        71.37      61.714444\n",
      "2024-11-09        72.17      66.944444\n",
      "2024-11-09          NaN      66.944444\n",
      "2024-11-10          NaN      66.944444\n",
      "2024-11-11        28.00      60.613333\n"
     ]
    }
   ],
   "source": [
    "# Make sure the index is datetime\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "# Now calculate the rolling mean\n",
    "df['7d_moving_avg'] = df['Measurement'].rolling('7D', min_periods=1).mean()\n",
    "\n",
    "print(df.head(15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1ebb72",
   "metadata": {},
   "source": [
    "# Task 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fe718d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample transactions:\n",
      "   Transaction ID  Amount        Date\n",
      "0               3  219.06  2024-11-03\n",
      "1              16  299.95  2024-11-05\n",
      "2              37  133.17  2024-11-13\n",
      "3              66  299.37  2024-11-16\n",
      "4              28  197.63  2024-11-18\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Transaction ID': range(1, n+1),\n",
    "    'Amount': [round(random.uniform(50, 500), 2) for _ in range(n)],\n",
    "    'Date': [fake.date_between(start_date='-1y', end_date='today') for _ in range(n)]\n",
    "})\n",
    "\n",
    "df.sort_values('Date', inplace=True)  # sort by date\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"Sample transactions:\")\n",
    "print(df.head())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fc76c3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First transaction exceeding cumulative threshold:\n",
      "Transaction ID            41\n",
      "Amount                499.11\n",
      "Date              2025-02-10\n",
      "cumsum               5167.12\n",
      "Name: 19, dtype: object\n",
      "========================================\n",
      "    Transaction ID  Amount        Date    cumsum\n",
      "0                3  219.06  2024-11-03    219.06\n",
      "1               16  299.95  2024-11-05    519.01\n",
      "2               37  133.17  2024-11-13    652.18\n",
      "3               66  299.37  2024-11-16    951.55\n",
      "4               28  197.63  2024-11-18   1149.18\n",
      "..             ...     ...         ...       ...\n",
      "95              24  362.39  2025-10-15  25020.54\n",
      "96              79  317.52  2025-10-20  25338.06\n",
      "97              95  233.90  2025-10-24  25571.96\n",
      "98              87  183.40  2025-10-28  25755.36\n",
      "99              11  325.88  2025-10-29  26081.24\n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df['cumsum'] = df['Amount'].cumsum()\n",
    "threshold = 5000\n",
    "first_exceed_idx = df[df['cumsum'] > threshold].index.min()\n",
    "first_exceed_row = df.loc[first_exceed_idx]\n",
    "\n",
    "print(\"First transaction exceeding cumulative threshold:\")\n",
    "print(first_exceed_row)\n",
    "print(\"==\"*20)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91100486",
   "metadata": {},
   "source": [
    "# Task 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "be930dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample DataFrame:\n",
      "        Category   Value      Item\n",
      "0       Clothing  464.49  Director\n",
      "1       Clothing  288.60      Hair\n",
      "2          Books  310.45       Gun\n",
      "3           Toys   52.65    Rather\n",
      "4          Books  352.70       Out\n",
      "..           ...     ...       ...\n",
      "195         Toys  224.44   Culture\n",
      "196  Electronics  100.64      They\n",
      "197  Electronics  288.53     Think\n",
      "198        Books  336.73      From\n",
      "199         Toys  401.90      West\n",
      "\n",
      "[200 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "n = 200 \n",
    "\n",
    "categories = ['Electronics', 'Clothing', 'Toys', 'Books']\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Category': [random.choice(categories) for _ in range(n)],\n",
    "    'Value': [round(random.uniform(10, 500), 2) for _ in range(n)],\n",
    "    'Item': [fake.word().capitalize() for _ in range(n)]\n",
    "})\n",
    "\n",
    "print(\"Sample DataFrame:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7ce146f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Category   Value      Item\n",
      "70         Books  496.60   Student\n",
      "126     Clothing  498.59     Human\n",
      "71   Electronics  491.91  Audience\n",
      "74          Toys  496.79      Find\n"
     ]
    }
   ],
   "source": [
    "# Option 2: using idxmax (one row per category)\n",
    "idx = df.groupby('Category')['Value'].idxmax()\n",
    "result = df.loc[idx]\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e357836",
   "metadata": {},
   "source": [
    "# Task 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4db9ca77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "    Transaction ID         Customer  \\\n",
      "0                1      Rachel Chan   \n",
      "1                2  Hunter Marshall   \n",
      "2                3    Samuel Barker   \n",
      "3                4    Connor Flores   \n",
      "4                5    Carolyn Hodge   \n",
      "..             ...              ...   \n",
      "95              96   Carmen Pacheco   \n",
      "96              97      Steven Ford   \n",
      "97              98   Joshua Hubbard   \n",
      "98              99     Regina Jones   \n",
      "99             100      Monica Snow   \n",
      "\n",
      "                                        Details  Purchase  \n",
      "0             {'city': 'Julianside', 'age': 48}    751.00  \n",
      "1             {'city': 'Tracyshire', 'age': 54}    233.51  \n",
      "2   {'city': 'Lake Christopherland', 'age': 58}    777.05  \n",
      "3             {'city': 'Bakermouth', 'age': 33}    120.94  \n",
      "4        {'city': 'South Malikfort', 'age': 59}    326.68  \n",
      "..                                          ...       ...  \n",
      "95           {'city': 'Garciashire', 'age': 51}    845.73  \n",
      "96              {'city': 'Cookberg', 'age': 52}    277.81  \n",
      "97        {'city': 'Johnsonchester', 'age': 54}     78.59  \n",
      "98          {'city': 'Wellsborough', 'age': 18}    463.30  \n",
      "99        {'city': 'Douglaschester', 'age': 66}     78.94  \n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Transaction ID': range(1, n+1),\n",
    "    'Customer': [fake.name() for _ in range(n)],\n",
    "    'Details': [{'city': fake.city(), 'age': random.randint(18, 70)} for _ in range(n)],\n",
    "    'Purchase': [round(random.uniform(10, 1000), 2) for _ in range(n)]\n",
    "})\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5059ac41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Flattened DataFrame:\n",
      "    Transaction ID         Customer  Purchase          Details_city  \\\n",
      "0                1      Rachel Chan    751.00            Julianside   \n",
      "1                2  Hunter Marshall    233.51            Tracyshire   \n",
      "2                3    Samuel Barker    777.05  Lake Christopherland   \n",
      "3                4    Connor Flores    120.94            Bakermouth   \n",
      "4                5    Carolyn Hodge    326.68       South Malikfort   \n",
      "..             ...              ...       ...                   ...   \n",
      "95              96   Carmen Pacheco    845.73           Garciashire   \n",
      "96              97      Steven Ford    277.81              Cookberg   \n",
      "97              98   Joshua Hubbard     78.59        Johnsonchester   \n",
      "98              99     Regina Jones    463.30          Wellsborough   \n",
      "99             100      Monica Snow     78.94        Douglaschester   \n",
      "\n",
      "    Details_age  \n",
      "0            48  \n",
      "1            54  \n",
      "2            58  \n",
      "3            33  \n",
      "4            59  \n",
      "..          ...  \n",
      "95           51  \n",
      "96           52  \n",
      "97           54  \n",
      "98           18  \n",
      "99           66  \n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "details_flat = pd.json_normalize(df['Details'])\n",
    "details_flat.columns = [f\"Details_{col}\" for col in details_flat.columns]\n",
    "\n",
    "df_flattened = pd.concat([df.drop(columns=['Details']), details_flat], axis=1)\n",
    "\n",
    "print(\"\\nFlattened DataFrame:\")\n",
    "print(df_flattened)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
